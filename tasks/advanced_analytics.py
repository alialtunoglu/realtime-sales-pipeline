"""
Advanced Analytics Tasks: RFM, CLTV ve Forecasting
Silver veriden ileri dÃ¼zey mÃ¼ÅŸteri analitiÄŸi
"""
import os
from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip
from pyspark.sql.functions import col, max as spark_max, count, sum as spark_sum, datediff, to_date, lit, expr

def run_advanced_analytics():
    """RFM, CLTV ve Forecasting analitiklerini Ã§alÄ±ÅŸtÄ±rÄ±r"""
    
    # Spark session
    builder = SparkSession.builder \
        .appName("AdvancedAnalytics") \
        .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
        .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
    
    spark = configure_spark_with_delta_pip(builder).getOrCreate()
    
    # Proje kÃ¶k dizinini bul (Airflow iÃ§in absolute path kullan)
    project_root = '/Users/alialtunoglu/Desktop/realtime-sales-pipeline'
    
    try:
        # Silver verisini yÃ¼kle (absolute path)
        silver_path = os.path.join(project_root, "delta/silver/online_retail_cleaned")
        print(f"ğŸ” Silver path: {silver_path}")
        
        # Path kontrolÃ¼
        if not os.path.exists(silver_path):
            raise FileNotFoundError(f"Silver tablo bulunamadÄ±: {silver_path}")
            
        df_silver = spark.read.format("delta").load(silver_path)
        
        print(f"ğŸ“Š Silver veri satÄ±r sayÄ±sÄ±: {df_silver.count()}")
        
        # 1ï¸âƒ£ RFM ANALÄ°ZÄ°
        print("ğŸ”„ RFM analizi hesaplanÄ±yor...")
        
        # En son tarih
        latest_date = df_silver.agg(spark_max("InvoiceDate")).collect()[0][0]
        print(f"ğŸ“… En son tarih: {latest_date}")
        
        # RFM hesaplama
        rfm = df_silver \
            .withColumn("InvoiceDateOnly", to_date("InvoiceDate")) \
            .groupBy("CustomerID") \
            .agg(
                datediff(lit(latest_date), spark_max("InvoiceDateOnly")).alias("Recency"),
                count("InvoiceNo").alias("Frequency"),
                spark_sum(col("Quantity") * col("UnitPrice")).alias("Monetary")
            )
        
        print(f"ğŸ“Š RFM mÃ¼ÅŸteri sayÄ±sÄ±: {rfm.count()}")
        
        # RFM kaydet
        rfm_path = os.path.join(project_root, "delta/gold/rfm_table")
        rfm.write.format("delta").mode("overwrite").save(rfm_path)
        
        # 2ï¸âƒ£ CLTV ANALÄ°ZÄ°
        print("ğŸ”„ CLTV analizi hesaplanÄ±yor...")
        
        # CLTV hesapla (basit formÃ¼l)
        cltv = rfm.withColumn(
            "CLTV", 
            (col("Frequency") * col("Monetary")) / (col("Recency") + lit(1))
        )
        
        # CLTV kaydet
        cltv_path = os.path.join(project_root, "delta/gold/cltv_table")
        cltv.write.format("delta").mode("overwrite").save(cltv_path)
        
        # 3ï¸âƒ£ FORECASTÄ°NG
        print("ğŸ”„ Forecasting analizi hesaplanÄ±yor...")
        
        # 12 aylÄ±k gelir tahmini
        forecast = cltv.withColumn("ExpectedRevenue_12M", col("CLTV") * lit(12))
        
        # Forecast kaydet
        forecast_path = os.path.join(project_root, "delta/gold/forecast_table")
        forecast.write.format("delta").mode("overwrite").save(forecast_path)
        
        print("âœ… Ä°leri dÃ¼zey analitik iÅŸlemleri tamamlandÄ±!")
        print("ğŸ“Š OluÅŸturulan tablolar:")
        print("   ğŸ¯ rfm_table (MÃ¼ÅŸteri Segmentasyonu)")
        print("   ğŸ’° cltv_table (MÃ¼ÅŸteri YaÅŸam Boyu DeÄŸeri)")
        print("   ğŸ”® forecast_table (12 AylÄ±k Gelir Tahmini)")
        
        # Ã–rnek veriler
        print("\nğŸ¯ RFM Analizi (Top 5):")
        rfm.orderBy(col("Monetary").desc()).show(5)
        
        print("\nğŸ’° CLTV Analizi (Top 5):")
        cltv.orderBy(col("CLTV").desc()).show(5)
        
        print("\nğŸ”® Forecasting (Top 5 Tahmini):")
        forecast.orderBy(col("ExpectedRevenue_12M").desc()).show(5)
        
    except Exception as e:
        print(f"âŒ Advanced analytics hatasÄ±: {str(e)}")
        raise e
    finally:
        spark.stop()

if __name__ == "__main__":
    run_advanced_analytics()
