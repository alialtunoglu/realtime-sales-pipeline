"""
Bronze Layer - Data Ingestion Task
CSV'den Delta formatÄ±na veri yÃ¼kleme
"""
import os
import sys
from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip

def run_bronze_ingestion():
    """CSV verisini Bronze katmanÄ±na Delta formatÄ±nda yÃ¼kler"""
    
    # Spark session
    builder = SparkSession.builder \
        .appName("RetailCSVIngestion") \
        .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
        .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
    
    spark = configure_spark_with_delta_pip(builder).getOrCreate()
    
    # Proje kÃ¶k dizinini bul (Airflow iÃ§in absolute path kullan)
    project_root = '/Users/alialtunoglu/Desktop/realtime-sales-pipeline'
    
    try:
        # CSV'den oku (absolute path)
        input_path = os.path.join(project_root, "data/input/retail_data.csv")
        print(f"ğŸ” Input path: {input_path}")
        
        # Path kontrolÃ¼
        if not os.path.exists(input_path):
            raise FileNotFoundError(f"CSV dosyasÄ± bulunamadÄ±: {input_path}")
            
        df = spark.read.format("csv") \
            .option("header", "true") \
            .option("inferSchema", "true") \
            .load(input_path)
        
        print(f"ğŸ“Š Okunan veri satÄ±r sayÄ±sÄ±: {df.count()}")
        df.printSchema()
        
        # Bronze'a Delta formatÄ±nda yaz (absolute path)
        output_path = os.path.join(project_root, "delta/bronze/online_retail")
        df.write.format("delta").mode("overwrite").option("overwriteSchema", "true").save(output_path)
        
        print("âœ… Bronze ingestion baÅŸarÄ±yla tamamlandÄ±.")
        print(f"ğŸ“ Veri kaydedildi: {output_path}")
        
    except Exception as e:
        print(f"âŒ Bronze ingestion hatasÄ±: {str(e)}")
        raise e
    finally:
        spark.stop()

if __name__ == "__main__":
    run_bronze_ingestion()
