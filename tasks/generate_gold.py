"""
Gold Layer - Aggregation & Analytics Task
Silver'dan analiz tablolarÄ±nÄ± oluÅŸturur
"""
import os
from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip
from pyspark.sql.functions import sum, count, to_date, col, avg, countDistinct

def run_gold_aggregation():
    """Silver verisinden Gold katmanÄ± analiz tablolarÄ±nÄ± oluÅŸturur"""
    
    # Spark session
    builder = SparkSession.builder \
        .appName("GoldAggregation") \
        .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
        .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
    
    spark = configure_spark_with_delta_pip(builder).getOrCreate()
    
    # Proje kÃ¶k dizinini bul (Airflow iÃ§in absolute path kullan)
    project_root = '/Users/alialtunoglu/Desktop/realtime-sales-pipeline'
    
    try:
        # Silver'dan oku (absolute path)
        silver_path = os.path.join(project_root, "delta/silver/online_retail_cleaned")
        print(f"ğŸ” Silver path: {silver_path}")
        
        # Path kontrolÃ¼
        if not os.path.exists(silver_path):
            raise FileNotFoundError(f"Silver tablo bulunamadÄ±: {silver_path}")
            
        df_silver = spark.read.format("delta").load(silver_path)
        
        print(f"ğŸ“Š Silver veri satÄ±r sayÄ±sÄ±: {df_silver.count()}")
        
        # GOLD #1: GÃ¼nlÃ¼k satÄ±ÅŸ toplamÄ±
        print("ğŸ”„ GÃ¼nlÃ¼k satÄ±ÅŸ agregasyonu hesaplanÄ±yor...")
        daily_sales = df_silver \
            .withColumn("SaleDate", to_date("InvoiceDate")) \
            .groupBy("SaleDate") \
            .agg(
                sum("Quantity").alias("TotalQuantity"),
                sum(df_silver["Quantity"] * df_silver["UnitPrice"]).alias("TotalRevenue"),
                countDistinct("CustomerID").alias("UniqueCustomers"),
                count("InvoiceNo").alias("TotalTransactions")
            ) \
            .orderBy("SaleDate")
        
        # GOLD #2: En Ã§ok satÄ±lan Ã¼rÃ¼nler (top 20)
        print("ğŸ”„ En Ã§ok satÄ±lan Ã¼rÃ¼nler hesaplanÄ±yor...")
        top_products = df_silver \
            .groupBy("StockCode", "Description") \
            .agg(
                sum("Quantity").alias("TotalSold"),
                sum(df_silver["Quantity"] * df_silver["UnitPrice"]).alias("TotalRevenue"),
                avg("UnitPrice").alias("AvgPrice")
            ) \
            .orderBy(col("TotalSold").desc()) \
            .limit(20)
        
        # GOLD #3: Ãœlke bazlÄ± satÄ±ÅŸ
        print("ğŸ”„ Ãœlke bazlÄ± satÄ±ÅŸ hesaplanÄ±yor...")
        country_sales = df_silver \
            .groupBy("Country") \
            .agg(
                sum(df_silver["Quantity"] * df_silver["UnitPrice"]).alias("CountryRevenue"),
                sum("Quantity").alias("TotalQuantity"),
                countDistinct("CustomerID").alias("UniqueCustomers"),
                countDistinct("StockCode").alias("UniqueProducts")
            ) \
            .orderBy(col("CountryRevenue").desc())
        
        # Kaydet
        print("ğŸ’¾ Gold tablolarÄ± kaydediliyor...")
        daily_sales.write.format("delta").mode("overwrite").option("overwriteSchema", "true").save(
            os.path.join(project_root, "delta/gold/daily_sales")
        )
        top_products.write.format("delta").mode("overwrite").option("overwriteSchema", "true").save(
            os.path.join(project_root, "delta/gold/top_products")
        )
        country_sales.write.format("delta").mode("overwrite").option("overwriteSchema", "true").save(
            os.path.join(project_root, "delta/gold/country_sales")
        )
        
        print("âœ… Gold aggregation iÅŸlemi tamamlandÄ±.")
        print("ğŸ“Š OluÅŸturulan tablolar:")
        print("   ğŸ“ˆ daily_sales")
        print("   ğŸ† top_products")  
        print("   ğŸŒ country_sales")
        
        # Ã–rnek veriler
        print("\nğŸ“‹ GÃ¼nlÃ¼k SatÄ±ÅŸ (Son 5 gÃ¼n):")
        daily_sales.show(5)
        
        print("\nğŸ† En Ã‡ok SatÄ±lan ÃœrÃ¼nler (Top 5):")
        top_products.show(5)
        
        print("\nğŸŒ Ãœlke BazlÄ± SatÄ±ÅŸ (Top 5):")
        country_sales.show(5)
        
    except Exception as e:
        print(f"âŒ Gold aggregation hatasÄ±: {str(e)}")
        raise e
    finally:
        spark.stop()

if __name__ == "__main__":
    run_gold_aggregation()
