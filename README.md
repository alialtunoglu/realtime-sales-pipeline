# ğŸ›ï¸ Real-time Sales Pipeline

Modern **Medallion Architecture** ile geliÅŸtirilmiÅŸ enterprise-grade retail satÄ±ÅŸ veri pipeline'Ä±. Apache Spark, Delta Lake, Apache Airflow, ve kapsamlÄ± monitoring sistemi ile production-ready veri iÅŸleme platformu.

[![CI/CD](https://github.com/alialtunoglu/realtime-sales-pipeline/workflows/Pipeline%20CI/CD/badge.svg)](https://github.com/alialtunoglu/realtime-sales-pipeline/actions)
[![Coverage](https://codecov.io/gh/alialtunoglu/realtime-sales-pipeline/branch/main/graph/badge.svg)](https://codecov.io/gh/alialtunoglu/realtime-sales-pipeline)
[![Quality Gate](https://sonarcloud.io/api/project_badges/measure?project=realtime-sales-pipeline&metric=alert_status)](https://sonarcloud.io/dashboard?id=realtime-sales-pipeline)

## ğŸ—ï¸ Sistem Mimarisi

```
ğŸ“ Data Sources â†’ ğŸ¥‰ Bronze â†’ ğŸ¥ˆ Silver â†’ ğŸ¥‡ Gold â†’ ğŸ¤– ML Models â†’ ğŸ“Š Dashboard
                    â†“         â†“         â†“          â†“
                 ğŸ” Monitoring & Alerting System
```

### Katmanlar:
- **ğŸ¥‰ Bronze:** Ham veri (Delta format, schema validation)
- **ğŸ¥ˆ Silver:** TemizlenmiÅŸ veri (Quality checks, business rules)  
- **ğŸ¥‡ Gold:** Ä°ÅŸ analitiÄŸi tablolarÄ± (Aggregated metrics)
- **ğŸ¤– ML Layer:** Forecasting & segmentation models
- **ï¿½ Monitoring:** Real-time health checks & alerting

## âœ¨ Ã–zellikler

### ğŸ“Š Veri Ä°ÅŸleme
- **Medallion Architecture** ile katmanlÄ± veri iÅŸleme
- **Delta Lake** ile ACID transactions ve time travel
- **Apache Spark** ile Ã¶lÃ§eklenebilir veri iÅŸleme
- **Apache Airflow** ile orkestrasyon

### ğŸ¤– Makine Ã–ÄŸrenmesi
- SatÄ±ÅŸ tahminleme (Sales Forecasting)
- MÃ¼ÅŸteri segmentasyonu (RFM Analysis)
- Customer Lifetime Value (CLTV) hesaplama
- Model performans izleme

### ğŸ” Monitoring & Observability
- Real-time sistem saÄŸlÄ±k kontrolÃ¼
- Veri kalitesi metrikleri
- Model performans izleme
- Otomatik alert sistemi
- Interactive dashboard (Streamlit)

### ğŸš€ Production Ready
- Docker containerization
- Kubernetes deployment manifests
- CI/CD pipeline (GitHub Actions)
- Comprehensive testing (55 unit tests)
- Security scanning
- Performance monitoring

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1ï¸âƒ£ Development Environment

```bash
# Repository'yi klonla
git clone https://github.com/alialtunoglu/realtime-sales-pipeline.git
cd realtime-sales-pipeline

# Virtual environment oluÅŸtur
python -m venv retail-analytics
source retail-analytics/bin/activate  # Linux/Mac
# retail-analytics\Scripts\activate  # Windows

# Dependencies kur
pip install -r requirements.txt
```

### 2ï¸âƒ£ Quick Start
```bash
# Pipeline'Ä± test et
python test_pipeline.sh

# Dashboard'u baÅŸlat
streamlit run dashboard/app.py

# Monitoring baÅŸlat
python monitoring.py run

# CLI aracÄ±nÄ± kullan
python -m src.monitoring.cli status
```

### 3ï¸âƒ£ Production Deployment

#### Docker Compose ile
```bash
# Production deployment
./deploy/deploy.sh production

# Servisleri kontrol et
docker-compose ps

# LoglarÄ± izle
docker-compose logs -f monitoring
```

#### Kubernetes ile
```bash
# Kubernetes'e deploy et
kubectl apply -f k8s/storage.yaml
kubectl apply -f k8s/deployment.yaml

# Servisleri kontrol et
kubectl get pods
kubectl get services
```
./test_pipeline.sh

# Tam pipeline
./run_complete_pipeline.sh
```

### 3ï¸âƒ£ Dashboard'u BaÅŸlat
```bash
streamlit run dashboard/app.py --server.port 8504
```

## ğŸ¤– Airflow Otomasyonu

### DAG'larÄ± Ã‡alÄ±ÅŸtÄ±r
```bash
# Airflow baÅŸlat
export AIRFLOW_HOME=$(pwd)/airflow
airflow webserver --port 8080 &
airflow scheduler &

# Pipeline tetikle
airflow dags trigger retail_sales_pipeline
```

### KullanÄ±labilir DAG'lar:
- `retail_sales_pipeline` - Tam pipeline
- `bronze_ingestion_dag` - Sadece Bronze layer
- `silver_cleaning_dag` - Sadece Silver layer

## ğŸ“Š OluÅŸturulan Tablolar

### Gold Layer:
- `daily_sales` - GÃ¼nlÃ¼k satÄ±ÅŸ Ã¶zetleri
- `top_products` - En Ã§ok satÄ±lan Ã¼rÃ¼nler  
- `country_sales` - Ãœlke bazlÄ± satÄ±ÅŸ

### Advanced Analytics:
- `rfm_table` - MÃ¼ÅŸteri segmentasyonu
- `cltv_table` - MÃ¼ÅŸteri yaÅŸam boyu deÄŸeri
- `forecast_table` - 12 aylÄ±k gelir tahminleri

## ğŸ“ Proje YapÄ±sÄ±

```
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                    # Airflow DAG dosyalarÄ±
â”‚   â””â”€â”€ airflow.cfg             # Airflow konfigÃ¼rasyonu
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                  # Streamlit dashboard
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/                  # Ham veri dosyalarÄ±
â”‚   â””â”€â”€ output/                 # Ä°ÅŸlenmiÅŸ veriler
â”œâ”€â”€ delta/                      # Delta Lake tablolarÄ±
â”‚   â”œâ”€â”€ bronze/                 # Ham veriler
â”‚   â”œâ”€â”€ silver/                 # TemizlenmiÅŸ veriler
â”‚   â””â”€â”€ gold/                   # Ä°ÅŸ analitiÄŸi
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks
â”‚   â”œâ”€â”€ Complete_Pipeline_Tutorial.ipynb
â”‚   â”œâ”€â”€ 01_ingestion.ipynb
â”‚   â”œâ”€â”€ 02_silver_cleaning.ipynb
â”‚   â”œâ”€â”€ 03_gold_aggregation.ipynb
â”‚   â”œâ”€â”€ gold_rfm.ipynb
â”‚   â”œâ”€â”€ gold_cltv.ipynb
â”‚   â””â”€â”€ gold_forecasting.ipynb
â”œâ”€â”€ tasks/                      # Pipeline task'leri
â”‚   â”œâ”€â”€ ingest_data.py          # Bronze layer
â”‚   â”œâ”€â”€ clean_data.py           # Silver layer
â”‚   â”œâ”€â”€ generate_gold.py        # Gold layer
â”‚   â””â”€â”€ advanced_analytics.py   # RFM, CLTV, Forecasting
â”œâ”€â”€ run_complete_pipeline.sh    # Tam pipeline script
â”œâ”€â”€ test_pipeline.sh           # HÄ±zlÄ± test script
â””â”€â”€ requirements.txt           # Python dependencies
```

## ğŸ› ï¸ Teknoloji Stack

- **Veri Ä°ÅŸleme:** Apache Spark + Delta Lake
- **Orchestration:** Apache Airflow
- **Visualization:** Streamlit + Plotly
- **Analytics:** PySpark SQL + MLlib
- **Storage:** Delta Lake (Parquet + Transaction Log)

## ğŸ“ˆ Analytics Ã–zellikleri

### RFM Analizi
- **Recency:** Son alÄ±ÅŸveriÅŸten bu yana geÃ§en gÃ¼n
- **Frequency:** Toplam alÄ±ÅŸveriÅŸ sayÄ±sÄ±  
- **Monetary:** Toplam harcama miktarÄ±

### CLTV (Customer Lifetime Value)
```
CLTV = (Frequency Ã— Monetary) / (Recency + 1)
```

### Forecasting
```
12 AylÄ±k Tahmini Gelir = CLTV Ã— 12
```

## ğŸ”§ KonfigÃ¼rasyon

### Spark AyarlarÄ±
```python
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")
```

### Delta Lake AyarlarÄ±
```python
spark.conf.set("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension")
spark.conf.set("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
```

## ğŸ“š Ã–ÄŸrenme KaynaklarÄ±

1. **ğŸ““ Complete_Pipeline_Tutorial.ipynb** - Tam tutorial
2. **ğŸ“Š Dashboard** - http://localhost:8504
3. **ğŸ¤– Airflow UI** - http://localhost:8080

## ğŸ› Sorun Giderme

### Streamlit TypeIs HatasÄ±
```bash
pip install --upgrade typing-extensions
```

### Spark Port Ã‡akÄ±ÅŸmasÄ±
```bash
# FarklÄ± port kullan
spark.conf.set("spark.ui.port", "4041")
```

### Delta Table Okuma HatasÄ±
```bash
# Cache temizle
spark.sql("CLEAR CACHE")
```

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

Medallion Architecture ve modern veri mÃ¼hendisliÄŸi prensipleri ile geliÅŸtirilmiÅŸtir.

---

**ğŸ¯ Bu proje ile neler Ã¶ÄŸreneceksiniz:**
- Modern veri mÃ¼hendisliÄŸi best practice'leri
- Apache Spark ile bÃ¼yÃ¼k veri iÅŸleme
- Delta Lake ile ACID transaction'lar
- Apache Airflow ile pipeline otomasyonu
- Streamlit ile real-time dashboard'lar
- RFM, CLTV ve forecasting analitiÄŸi
